{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matan034/Knee-Bone-Segmentation/blob/main/KneeProject_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylZAVlS5lzLZ"
      },
      "source": [
        "#Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9XGtR_olxU2"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQU3Y3hFl9HB",
        "outputId": "9326bc69-7c11-4eb9-94da-a5d18df0af2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "SEED = 909\n",
        "BATCH_SIZE_TRAIN = 64\n",
        "BATCH_SIZE_TEST = 64\n",
        "BATCH_SIZE_VALIDATION = 1\n",
        "\n",
        "IMAGE_HEIGHT =  256\n",
        "IMAGE_WIDTH = 256\n",
        "IMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "IS_BOUNDARY_PATH = False\n",
        "\n",
        "if IS_BOUNDARY_PATH:\n",
        "  data_dir_train_image = '/content/drive/My Drive/KneeProject/trainingBoundary/img/'  #when using boundary images go to path trainingBoundary regular images in training\n",
        "  data_dir_train_mask = '/content/drive/My Drive/KneeProject/trainingBoundary/mask/'\n",
        "\n",
        "  data_dir_test_image = '/content/drive/My Drive/KneeProject/testingBoundary/img/'  #when creating boundary images go to path testingBoundary regular images in testing\n",
        "  data_dir_test_mask = '/content/drive/My Drive/KneeProject/testingBoundary/mask/'\n",
        "\n",
        "  data_dir_val_image = '/content/drive/My Drive/KneeProject/validationBoundary/img/' #when creating boundary images go to path validationBoundary regular images in validation\n",
        "  data_dir_val_mask = '/content/drive/My Drive/KneeProject/validationBoundary/mask/'\n",
        "else:\n",
        "   data_dir_train_image = '/content/drive/My Drive/KneeProject/training/img/'  #when using boundary images go to path trainingBoundary regular images in training\n",
        "   data_dir_train_mask = '/content/drive/My Drive/KneeProject/training/mask/'\n",
        "\n",
        "   data_dir_test_image = '/content/drive/My Drive/KneeProject/testing/img/'  #when creating boundary images go to path testingBoundary regular images in testing\n",
        "   data_dir_test_mask = '/content/drive/My Drive/KneeProject/testing/mask/'\n",
        "\n",
        "   data_dir_val_image = '/content/drive/My Drive/KneeProject/validation/img/' #when creating boundary images go to path validationBoundary regular images in validation\n",
        "   data_dir_val_mask = '/content/drive/My Drive/KneeProject/validation/mask/'\n",
        "\n",
        "\n",
        "NUM_TRAIN = len(os.listdir(data_dir_train_image+\"femur\"))\n",
        "NUM_TEST = len(os.listdir(data_dir_test_image+\"femur\"))\n",
        "NUM_VAL = len(os.listdir(data_dir_val_image+\"femur\"))\n",
        "\n",
        "NUM_OF_EPOCHS = 100\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "EPOCH_STEP_TRAIN = NUM_TRAIN // BATCH_SIZE_TRAIN\n",
        "EPOCH_STEP_TEST = NUM_TEST // BATCH_SIZE_TEST\n",
        "\n",
        "LOSS_FUNC_DICE=True\n",
        "LOSS_FUNC_TRAV=False\n",
        "USE_IOU = True\n",
        "TRANSFER_LEARNING = True\n",
        "CLASSIFIER =False\n",
        "EXTRA_LAYER = True\n",
        "UNET_MODEL_TO_TRAIN=\"attention\" # OPTIONS : \"unet\", \"attention\", \"3plus\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o9uJFu6EwlV"
      },
      "source": [
        "# Data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axahajake651",
        "outputId": "abca1b5f-9b75-47a1-cbff-b0c37cce08e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9314 trainig images\n",
            "9314 trainig mask\n",
            "2336 test images\n",
            "2336 test mask\n",
            "1052 validation images\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir(data_dir_train_image+\"/femur\")),\"trainig images\")\n",
        "print(len(os.listdir(data_dir_train_mask+\"/femur\")),\"trainig mask\")\n",
        "print(len(os.listdir(data_dir_test_image+\"/femur\")),\"test images\")\n",
        "print(len(os.listdir(data_dir_test_mask+\"/femur\")),\"test mask\")\n",
        "print(len(os.listdir(data_dir_val_image+\"/femur\")),\"validation images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpXJ_t-2l_zw"
      },
      "outputs": [],
      "source": [
        "def create_segmentation_generator_train(img_path, msk_path, BATCH_SIZE):\n",
        "    data_gen_args = dict(rescale=1./255,\n",
        "#                         featurewise_center=True,\n",
        "#                      featurewise_std_normalization=True,\n",
        "#                          rotation_range=90\n",
        "#                      width_shift_range=0.2,\n",
        "#                      height_shift_range=0.2,\n",
        "#                      zoom_range=0.3\n",
        "                        )\n",
        "    datagen = ImageDataGenerator(**data_gen_args)\n",
        "    class_mode_selection = 'grayscale'\n",
        "    if TRANSFER_LEARNING or CLASSIFIER:\n",
        "      class_mode_selection = 'rgb'\n",
        "    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, color_mode=class_mode_selection,class_mode=None,  batch_size=BATCH_SIZE, seed=SEED) #color_mode='grayscale'\n",
        "    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, color_mode=class_mode_selection,class_mode=None, batch_size=BATCH_SIZE, seed=SEED) #color_mode='grayscale'\n",
        "\n",
        "    return zip(img_generator, msk_generator)\n",
        "\n",
        "# Remember not to perform any image augmentation in the test generator!\n",
        "def create_segmentation_generator_test(img_path, msk_path, BATCH_SIZE):\n",
        "    data_gen_args = dict(rescale=1./255)\n",
        "    datagen = ImageDataGenerator(**data_gen_args)\n",
        "    class_mode_selection = 'grayscale'\n",
        "    if TRANSFER_LEARNING or CLASSIFIER:\n",
        "      class_mode_selection = 'rgb'\n",
        "    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, color_mode=class_mode_selection,class_mode=None,  batch_size=BATCH_SIZE, seed=SEED) #color_mode='grayscale'\n",
        "    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, color_mode=class_mode_selection,class_mode=None,  batch_size=BATCH_SIZE, seed=SEED) #color_mode='grayscale'\n",
        "\n",
        "    return zip(img_generator, msk_generator)\n",
        "\n",
        "def create_segmentation_generator_validation(img_path, msk_path, BATCH_SIZE):\n",
        "    data_gen_args = dict(rescale=1./255)\n",
        "    datagen = ImageDataGenerator(**data_gen_args)\n",
        "    class_mode_selection = 'grayscale'\n",
        "    if TRANSFER_LEARNING or CLASSIFIER:\n",
        "      class_mode_selection = 'rgb'\n",
        "    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, color_mode=class_mode_selection,class_mode=None,  batch_size=BATCH_SIZE, seed=SEED) #color_mode='grayscale'\n",
        "    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, color_mode=class_mode_selection,class_mode=None,  batch_size=BATCH_SIZE, seed=SEED) #color_mode='grayscale'\n",
        "    return zip(img_generator, msk_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9-MkgwymB3g",
        "outputId": "d14555e9-aa74-45e5-d088-da7fe1572c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9314 images belonging to 1 classes.\n",
            "Found 9314 images belonging to 1 classes.\n",
            "Found 2336 images belonging to 1 classes.\n",
            "Found 2336 images belonging to 1 classes.\n",
            "Found 1052 images belonging to 1 classes.\n",
            "Found 1052 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = create_segmentation_generator_train(data_dir_train_image, data_dir_train_mask, BATCH_SIZE_TRAIN)\n",
        "test_generator = create_segmentation_generator_test(data_dir_test_image, data_dir_test_mask, BATCH_SIZE_TEST)\n",
        "validation_generator = create_segmentation_generator_validation(data_dir_val_image, data_dir_val_mask, BATCH_SIZE_VALIDATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9clzp0AmEKc"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15,15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj4QuiB5mGGl"
      },
      "outputs": [],
      "source": [
        "def show_dataset(datagen, num=1):\n",
        "    for i in range(0,num):\n",
        "        image,mask = next(datagen)\n",
        "        display([image[0], mask[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMwmjrKEmIAE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "66089739-01c2-46e8-e2b1-4e7bdb0a6d1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1542acbcb8da>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-693b1012436a>\u001b[0m in \u001b[0;36mshow_dataset\u001b[0;34m(datagen, num)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    371\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "show_dataset(train_generator, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdfVw5BZD2SM"
      },
      "source": [
        "# Unets\n",
        "Base Unet\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyFR5VJdmLiM"
      },
      "outputs": [],
      "source": [
        "#put refrence here\n",
        "def unet(n_levels, initial_features=32, n_blocks=2, kernel_size=3, pooling_size=2, in_channels=1, out_channels=1):\n",
        "    inputs = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, in_channels))\n",
        "    x = inputs\n",
        "\n",
        "    convpars = dict(kernel_size=kernel_size, activation='relu', padding='same')\n",
        "\n",
        "    #downstream\n",
        "    skips = {}\n",
        "    for level in range(n_levels):\n",
        "        for _ in range(n_blocks):\n",
        "            x = keras.layers.Conv2D(initial_features * (2 ** level), **convpars)(x)\n",
        "        if level < n_levels - 1:\n",
        "            skips[level] = x\n",
        "            x = keras.layers.MaxPool2D(pooling_size)(x)\n",
        "\n",
        "    # upstream\n",
        "    for level in reversed(range(n_levels-1)):\n",
        "        x = keras.layers.Conv2DTranspose(initial_features * (2 ** level), strides=pooling_size, **convpars)(x)\n",
        "        x = keras.layers.Concatenate()([x, skips[level]])\n",
        "        for _ in range(n_blocks):\n",
        "            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n",
        "\n",
        "    # output\n",
        "    activation = 'sigmoid' if out_channels == 1 else 'softmax'\n",
        "    x = keras.layers.Conv2D(out_channels, kernel_size=1, activation=activation, padding='same')(x)\n",
        "\n",
        "    return keras.Model(inputs=[inputs], outputs=[x], name=f'UNET-L{n_levels}-F{initial_features}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTkQMadVD719"
      },
      "source": [
        "Attention Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwrRle8fjU3l"
      },
      "outputs": [],
      "source": [
        "#put refrence here\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.layers import Conv2D,GlobalAveragePooling2D\n",
        "from keras.applications import ResNet50,VGG16\n",
        "\n",
        "class attention_unet():\n",
        "  def __init__(self,img_rows=512,img_cols=512,tl=False,classifier=False, extra_layer = False):\n",
        "    self.img_rows=img_rows\n",
        "    self.img_cols=img_cols\n",
        "    if tl or classifier:\n",
        "      self.img_shape=(self.img_rows,self.img_cols,3)\n",
        "    else:\n",
        "      self.img_shape=(self.img_rows,self.img_cols,1)\n",
        "    self.df=64\n",
        "    self.uf=64\n",
        "    self.tl=tl\n",
        "    self.classifier=classifier\n",
        "    self.extra_layer = extra_layer\n",
        "\n",
        "  def build_unet(self):\n",
        "    def conv2d(layer_input,filters,dropout_rate=0,bn=False):\n",
        "      d = conv1d(layer_input,filters,dropout_rate,bn)\n",
        "      d = conv1d(d,filters,dropout_rate,bn)\n",
        "      if dropout_rate:\n",
        "        d=layers.Dropout(dropout_rate)(d)\n",
        "      return d\n",
        "\n",
        "    def conv1d(layer_input,filters,dropout_rate=0,bn=False):\n",
        "      d=layers.Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(layer_input)\n",
        "      if bn:\n",
        "        d=layers.BatchNormalization()(d)\n",
        "      d=layers.Activation('relu')(d)\n",
        "      return d\n",
        "\n",
        "    def deconv2d(layer_input,filters,bn=False):\n",
        "      u=layers.UpSampling2D((2,2))(layer_input)\n",
        "      u=layers.Conv2D(filters,kernel_size=(3,3),strides=(1,1),padding='same')(u)\n",
        "      if bn:\n",
        "        u=layers.BatchNormalization()(u)\n",
        "      u=layers.Activation('relu')(u)\n",
        "\n",
        "      return u\n",
        "\n",
        "    def attention_block(F_g,F_l,F_int,bn=False):\n",
        "      g=layers.Conv2D(F_int,kernel_size=(1,1),strides=(1,1),padding='valid')(F_g)\n",
        "      if bn:\n",
        "        g=layers.BatchNormalization()(g)\n",
        "      x=layers.Conv2D(F_int,kernel_size=(1,1),strides=(1,1),padding='valid')(F_l)\n",
        "      if bn:\n",
        "        x=layers.BatchNormalization()(x)\n",
        "      psi=layers.Add()([g,x])\n",
        "      psi=layers.Activation('relu')(psi)\n",
        "\n",
        "      psi=layers.Conv2D(1,kernel_size=(1,1),strides=(1,1),padding='valid')(psi)\n",
        "\n",
        "      if bn:\n",
        "        psi=layers.BatchNormalization()(psi)\n",
        "      psi=layers.Activation('sigmoid')(psi)\n",
        "\n",
        "      return layers.Multiply()([F_l,psi])\n",
        "\n",
        "    inputs = layers.Input(shape=self.img_shape, name=\"input_1\")\n",
        "    if self.tl:\n",
        "      resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "      conv1 = resnet50.get_layer(\"input_1\").output\n",
        "      conv2 = resnet50.get_layer(\"conv1_relu\").output\n",
        "      conv3 = resnet50.get_layer(\"conv2_block3_out\").output\n",
        "      conv4 = resnet50.get_layer(\"conv3_block4_out\").output\n",
        "      if self.extra_layer:\n",
        "        conv5 = resnet50.get_layer(\"conv4_block6_out\").output\n",
        "        pool5=layers.MaxPooling2D((2,2))(conv5)\n",
        "        mid_block=conv2d(pool5,self.df*16,dropout_rate=0.5,bn=True)\n",
        "      else:\n",
        "        mid_block=resnet50.get_layer(\"conv4_block6_out\").output\n",
        "    else:\n",
        "      conv1=conv2d(inputs,self.df)\n",
        "      pool1=layers.MaxPooling2D((2,2))(conv1)\n",
        "\n",
        "      conv2=conv2d(pool1,self.df*2,bn=True)\n",
        "      pool2=layers.MaxPooling2D((2,2))(conv2)\n",
        "      conv3=conv2d(pool2,self.df*4,bn=True)\n",
        "      pool3=layers.MaxPooling2D((2,2))(conv3)\n",
        "\n",
        "      conv4=conv2d(pool3,self.df*8,bn=True)\n",
        "      pool4=layers.MaxPooling2D((2,2))(conv4)\n",
        "\n",
        "      if self.extra_layer:\n",
        "        conv5 = conv2d(pool4,self.df*8,dropout_rate=0.5,bn=True)\n",
        "        pool5=layers.MaxPooling2D((2,2))(conv5)\n",
        "        mid_block=conv2d(pool5,self.df*16,dropout_rate=0.5,bn=True)\n",
        "      else:\n",
        "        mid_block = mid_block=conv2d(pool4,self.df*16,dropout_rate=0.5,bn=True)\n",
        "\n",
        "    if self.extra_layer:\n",
        "      up5 = deconv2d(mid_block,self.uf*8,bn=True)\n",
        "      extra_conv=attention_block(up5,conv5,self.uf*8,bn=True)\n",
        "      extra_up=layers.Concatenate()([up5,extra_conv])\n",
        "      extra_conv=conv2d(extra_up,self.uf*8)\n",
        "      mid_block = extra_conv\n",
        "\n",
        "    up6=deconv2d(mid_block,self.uf*8,bn=True)\n",
        "    conv6=attention_block(up6,conv4,self.uf*8,bn=True)\n",
        "    up6=layers.Concatenate()([up6,conv6])\n",
        "    conv6=conv2d(up6,self.uf*8)\n",
        "\n",
        "    up7=deconv2d(conv6,self.uf*4,bn=True)\n",
        "    conv7=attention_block(up7,conv3,self.uf*4,bn=True)\n",
        "    up7=layers.Concatenate()([up7,conv7])\n",
        "    conv7=conv2d(up7,self.uf*4)\n",
        "\n",
        "    up8=deconv2d(conv7,self.uf*2,bn=True)\n",
        "    conv8=attention_block(up8,conv2,self.uf*2,bn=True)\n",
        "    up8=layers.Concatenate()([up8,conv8])\n",
        "    conv8=conv2d(up8,self.uf*2)\n",
        "\n",
        "    up9=deconv2d(conv8,self.uf,bn=True)\n",
        "    conv9=attention_block(up9,conv1,self.uf,bn=True)\n",
        "    up9=layers.Concatenate()([up9,conv9])\n",
        "    conv9=conv2d(up9,self.uf)\n",
        "\n",
        "    if self.classifier or self.tl:\n",
        "      output_channel = 3\n",
        "    else:\n",
        "      output_channel = 1\n",
        "    if self.classifier:\n",
        "      outputs=layers.Conv2D(output_channel,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(conv9)\n",
        "      vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_shape=self.img_shape,input_tensor=inputs)\n",
        "      for layer in vgg16.layers:\n",
        "            layer.trainable = False\n",
        "      b1 = vgg16.get_layer(\"block5_conv3\").output\n",
        "      concateBridge=layers.Concatenate()([mid_block,b1])\n",
        "      cls = Conv2D(32, (3,3), activation='relu', padding='same')(concateBridge)  # connected to mid_block\n",
        "      cls = Conv2D(3, (1,1))(cls)\n",
        "      cls = GlobalAveragePooling2D()(cls)\n",
        "      cls = layers.Activation('sigmoid')(cls)\n",
        "      clsr = layers.Reshape((1, 1, 3), name='classification')(cls)\n",
        "      out_with_cls = layers.multiply(inputs=[outputs,clsr], name='segmentation')\n",
        "      model=Model(inputs=inputs,outputs=out_with_cls,name=\"Attention-UNET\")\n",
        "    else:\n",
        "      outputs=layers.Conv2D(output_channel,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(conv9)\n",
        "      model=Model(inputs=inputs,outputs=outputs,name=\"Attention-UNET\")\n",
        "    return model\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nlh963ND-4-"
      },
      "source": [
        "Unet 3 plus (no deep no cgm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDXjGqHPptzu"
      },
      "outputs": [],
      "source": [
        "#https://github.com/hamidriasat/UNet-3-Plus/blob/69bcb36169191f57846029e6d2592c750ae8b7d6/models/unet3plus.py\n",
        "import keras as k\n",
        "def conv_block(x, kernels, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
        "               is_bn=True, is_relu=True, n=2):\n",
        "    \"\"\" Custom function for conv2d:\n",
        "        Apply  3*3 convolutions with BN and relu.\n",
        "    \"\"\"\n",
        "    for i in range(1, n + 1):\n",
        "        x = k.layers.Conv2D(filters=kernels, kernel_size=kernel_size,\n",
        "                            padding=padding, strides=strides,\n",
        "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
        "                            kernel_initializer=k.initializers.he_normal(seed=5))(x)\n",
        "        if is_bn:\n",
        "            x = k.layers.BatchNormalization()(x)\n",
        "        if is_relu:\n",
        "            x = k.activations.relu(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def unet3plus(input_shape, output_channels):\n",
        "    \"\"\" UNet3+ base model \"\"\"\n",
        "    filters = [64, 128, 256, 512, 1024]\n",
        "\n",
        "    input_layer = k.layers.Input(\n",
        "        shape=input_shape,\n",
        "        name=\"input_layer\"\n",
        "    )  # 320*320*3\n",
        "\n",
        "    \"\"\" Encoder\"\"\"\n",
        "    # block 1\n",
        "    e1 = conv_block(input_layer, filters[0])  # 320*320*64\n",
        "\n",
        "    # block 2\n",
        "    e2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 160*160*64\n",
        "    e2 = conv_block(e2, filters[1])  # 160*160*128\n",
        "\n",
        "    # block 3\n",
        "    e3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 80*80*128\n",
        "    e3 = conv_block(e3, filters[2])  # 80*80*256\n",
        "\n",
        "    # block 4\n",
        "    e4 = k.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 40*40*256\n",
        "    e4 = conv_block(e4, filters[3])  # 40*40*512\n",
        "\n",
        "    # block 5\n",
        "    # bottleneck layer\n",
        "    e5 = k.layers.MaxPool2D(pool_size=(2, 2))(e4)  # 20*20*512\n",
        "    e5 = conv_block(e5, filters[4])  # 20*20*1024\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    cat_channels = filters[0]\n",
        "    cat_blocks = len(filters)\n",
        "    upsample_channels = cat_blocks * cat_channels\n",
        "\n",
        "    \"\"\" d4 \"\"\"\n",
        "    e1_d4 = k.layers.MaxPool2D(pool_size=(8, 8))(e1)  # 320*320*64  --> 40*40*64\n",
        "    e1_d4 = conv_block(e1_d4, cat_channels, n=1)  # 320*320*64  --> 40*40*64\n",
        "\n",
        "    e2_d4 = k.layers.MaxPool2D(pool_size=(4, 4))(e2)  # 160*160*128 --> 40*40*128\n",
        "    e2_d4 = conv_block(e2_d4, cat_channels, n=1)  # 160*160*128 --> 40*40*64\n",
        "\n",
        "    e3_d4 = k.layers.MaxPool2D(pool_size=(2, 2))(e3)  # 80*80*256  --> 40*40*256\n",
        "    e3_d4 = conv_block(e3_d4, cat_channels, n=1)  # 80*80*256  --> 40*40*64\n",
        "\n",
        "    e4_d4 = conv_block(e4, cat_channels, n=1)  # 40*40*512  --> 40*40*64\n",
        "\n",
        "    e5_d4 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)  # 80*80*256  --> 40*40*256\n",
        "    e5_d4 = conv_block(e5_d4, cat_channels, n=1)  # 20*20*1024  --> 20*20*64\n",
        "\n",
        "    d4 = k.layers.concatenate([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
        "    d4 = conv_block(d4, upsample_channels, n=1)  # 40*40*320  --> 40*40*320\n",
        "\n",
        "    \"\"\" d3 \"\"\"\n",
        "    e1_d3 = k.layers.MaxPool2D(pool_size=(4, 4))(e1)  # 320*320*64 --> 80*80*64\n",
        "    e1_d3 = conv_block(e1_d3, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
        "\n",
        "    e2_d3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 160*160*256 --> 80*80*256\n",
        "    e2_d3 = conv_block(e2_d3, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
        "\n",
        "    e3_d3 = conv_block(e3, cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
        "\n",
        "    e4_d3 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)  # 40*40*320 --> 80*80*320\n",
        "    e4_d3 = conv_block(e4_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    e5_d3 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
        "    e5_d3 = conv_block(e5_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    d3 = k.layers.concatenate([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3])\n",
        "    d3 = conv_block(d3, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
        "\n",
        "    \"\"\" d2 \"\"\"\n",
        "    e1_d2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 320*320*64 --> 160*160*64\n",
        "    e1_d2 = conv_block(e1_d2, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
        "\n",
        "    e2_d2 = conv_block(e2, cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
        "\n",
        "    d3_d2 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d3)  # 80*80*320 --> 160*160*320\n",
        "    d3_d2 = conv_block(d3_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d4_d2 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d4)  # 40*40*320 --> 160*160*320\n",
        "    d4_d2 = conv_block(d4_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    e5_d2 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
        "    e5_d2 = conv_block(e5_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d2 = k.layers.concatenate([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
        "    d2 = conv_block(d2, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
        "\n",
        "    \"\"\" d1 \"\"\"\n",
        "    e1_d1 = conv_block(e1, cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
        "\n",
        "    d2_d1 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d2)  # 160*160*320 --> 320*320*320\n",
        "    d2_d1 = conv_block(d2_d1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d3_d1 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d3)  # 80*80*320 --> 320*320*320\n",
        "    d3_d1 = conv_block(d3_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d4_d1 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(d4)  # 40*40*320 --> 320*320*320\n",
        "    d4_d1 = conv_block(d4_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    e5_d1 = k.layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 --> 320*320*320\n",
        "    e5_d1 = conv_block(e5_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d1 = k.layers.concatenate([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1, ])\n",
        "    d1 = conv_block(d1, upsample_channels, n=1)  # 320*320*320 --> 320*320*320\n",
        "\n",
        "    # last layer does not have batchnorm and relu\n",
        "    d = conv_block(d1, output_channels, n=1, is_bn=False, is_relu=False)\n",
        "\n",
        "    output = k.activations.softmax(d)\n",
        "\n",
        "    return tf.keras.Model(inputs=input_layer, outputs=[output], name='UNet_3Plus')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "levwwHhMEGm8"
      },
      "source": [
        "# loss functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O88rhgjZh8cG"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    # Flatten the inputs\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "\n",
        "    # Calculate the intersection and union\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f)\n",
        "\n",
        "    # Calculate the Dice coefficient\n",
        "    dice_coef = (2.0 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    return dice_coef\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "def tversky(y_true, y_pred,smooth = 1):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "# Evaluation metrics: iou\n",
        "def iou(y_true, y_pred, smooth = 1.):\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    sum_ = K.sum(y_true) + K.sum(y_pred)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vniWhVcMEmj-"
      },
      "source": [
        "# Compile, train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llqEigJUzh00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58329e63-a494-4dbb-f34a-8eb10641ed7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "if UNET_MODEL_TO_TRAIN ==  \"unet\":\n",
        "    model = unet(4)\n",
        "if UNET_MODEL_TO_TRAIN == \"attention\":\n",
        "    a=attention_unet(img_rows=IMAGE_HEIGHT, img_cols=IMAGE_WIDTH,classifier=CLASSIFIER, tl = TRANSFER_LEARNING , extra_layer = EXTRA_LAYER)\n",
        "    model=a.build_unet()\n",
        "if UNET_MODEL_TO_TRAIN == \"3plus\":\n",
        "    INPUT_SHAPE = [IMAGE_HEIGHT, IMAGE_WIDTH, 1]\n",
        "    OUTPUT_CHANNELS = 1\n",
        "    model = unet3plus(INPUT_SHAPE, OUTPUT_CHANNELS)\n",
        "if LOSS_FUNC_DICE:\n",
        "  loss_func=dice_coef_loss\n",
        "  metric_func=dice_coefficient\n",
        "if LOSS_FUNC_TRAV:\n",
        "  loss_func=focal_tversky\n",
        "  metric_func=tversky\n",
        "if USE_IOU:\n",
        "  metric_func=iou\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss=loss_func, metrics=metric_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWm7_BQymPfB",
        "outputId": "10e95561-571b-44a9-954b-1a712154245a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Attention-UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 70, 70, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 32, 32, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 32, 32, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 34, 34, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 16, 16, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 16, 16, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 8, 8, 512)    131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 8, 8, 512)    0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 8, 8, 512)    0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 4, 4, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 4, 4, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 2, 2, 1024)  0           ['conv4_block6_out[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)            (None, 2, 2, 1024)   9438208     ['max_pooling2d_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_192[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 2, 2, 1024)   0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)            (None, 2, 2, 1024)   9438208     ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_193[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 2, 2, 1024)   0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 2, 2, 1024)   0           ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " up_sampling2d_25 (UpSampling2D  (None, 4, 4, 1024)  0           ['dropout_4[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)            (None, 4, 4, 512)    4719104     ['up_sampling2d_25[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 4, 4, 512)   2048        ['conv2d_194[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 4, 4, 512)    0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_195 (Conv2D)            (None, 4, 4, 512)    262656      ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_196 (Conv2D)            (None, 4, 4, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 4, 4, 512)   2048        ['conv2d_195[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 4, 4, 512)   2048        ['conv2d_196[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 4, 4, 512)    0           ['batch_normalization_129[0][0]',\n",
            "                                                                  'batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 4, 4, 512)    0           ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_197 (Conv2D)            (None, 4, 4, 1)      513         ['activation_162[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 4, 4, 1)     4           ['conv2d_197[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 4, 4, 1)      0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " multiply_25 (Multiply)         (None, 4, 4, 1024)   0           ['conv4_block6_out[0][0]',       \n",
            "                                                                  'activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 4, 4, 1536)   0           ['activation_161[0][0]',         \n",
            "                                                                  'multiply_25[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)            (None, 4, 4, 512)    7078400     ['concatenate_28[0][0]']         \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 4, 4, 512)    0           ['conv2d_198[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)            (None, 4, 4, 512)    2359808     ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 4, 4, 512)    0           ['conv2d_199[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_26 (UpSampling2D  (None, 8, 8, 512)   0           ['activation_165[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)            (None, 8, 8, 512)    2359808     ['up_sampling2d_26[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 8, 8, 512)   2048        ['conv2d_200[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 8, 8, 512)    0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)            (None, 8, 8, 512)    262656      ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)            (None, 8, 8, 512)    262656      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 8, 8, 512)   2048        ['conv2d_201[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 8, 8, 512)   2048        ['conv2d_202[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 8, 8, 512)    0           ['batch_normalization_133[0][0]',\n",
            "                                                                  'batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 8, 8, 512)    0           ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)            (None, 8, 8, 1)      513         ['activation_167[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 8, 8, 1)     4           ['conv2d_203[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 8, 8, 1)      0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " multiply_26 (Multiply)         (None, 8, 8, 512)    0           ['conv3_block4_out[0][0]',       \n",
            "                                                                  'activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (None, 8, 8, 1024)   0           ['activation_166[0][0]',         \n",
            "                                                                  'multiply_26[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)            (None, 8, 8, 512)    4719104     ['concatenate_29[0][0]']         \n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 8, 8, 512)    0           ['conv2d_204[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)            (None, 8, 8, 512)    2359808     ['activation_169[0][0]']         \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 8, 8, 512)    0           ['conv2d_205[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_27 (UpSampling2D  (None, 16, 16, 512)  0          ['activation_170[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)            (None, 16, 16, 256)  1179904     ['up_sampling2d_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 16, 16, 256)  1024       ['conv2d_206[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 16, 16, 256)  0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)            (None, 16, 16, 256)  65792       ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)            (None, 16, 16, 256)  65792       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 16, 16, 256)  1024       ['conv2d_207[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 16, 16, 256)  1024       ['conv2d_208[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 16, 16, 256)  0           ['batch_normalization_137[0][0]',\n",
            "                                                                  'batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 16, 16, 256)  0           ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)            (None, 16, 16, 1)    257         ['activation_172[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 16, 16, 1)   4           ['conv2d_209[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 16, 16, 1)    0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " multiply_27 (Multiply)         (None, 16, 16, 256)  0           ['conv2_block3_out[0][0]',       \n",
            "                                                                  'activation_173[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (None, 16, 16, 512)  0           ['activation_171[0][0]',         \n",
            "                                                                  'multiply_27[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)            (None, 16, 16, 256)  1179904     ['concatenate_30[0][0]']         \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 16, 16, 256)  0           ['conv2d_210[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)            (None, 16, 16, 256)  590080      ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 16, 16, 256)  0           ['conv2d_211[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_28 (UpSampling2D  (None, 32, 32, 256)  0          ['activation_175[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)            (None, 32, 32, 128)  295040      ['up_sampling2d_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 32, 32, 128)  512        ['conv2d_212[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 32, 32, 128)  0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)            (None, 32, 32, 128)  16512       ['activation_176[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)            (None, 32, 32, 128)  8320        ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 32, 32, 128)  512        ['conv2d_213[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 32, 32, 128)  512        ['conv2d_214[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 32, 32, 128)  0           ['batch_normalization_141[0][0]',\n",
            "                                                                  'batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 32, 32, 128)  0           ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)            (None, 32, 32, 1)    129         ['activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 32, 32, 1)   4           ['conv2d_215[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 32, 32, 1)    0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)         (None, 32, 32, 64)   0           ['conv1_relu[0][0]',             \n",
            "                                                                  'activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 32, 32, 192)  0           ['activation_176[0][0]',         \n",
            "                                                                  'multiply_28[0][0]']            \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 64, 64, 64)   1792        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)            (None, 32, 32, 128)  221312      ['concatenate_31[0][0]']         \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 64, 64, 64)   36928       ['block1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 32, 32, 128)  0           ['conv2d_216[0][0]']             \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 32, 32, 64)   0           ['block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)            (None, 32, 32, 128)  147584      ['activation_179[0][0]']         \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 32, 32, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 32, 32, 128)  0           ['conv2d_217[0][0]']             \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 32, 32, 128)  147584      ['block2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_29 (UpSampling2D  (None, 64, 64, 128)  0          ['activation_180[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 16, 16, 128)  0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)            (None, 64, 64, 64)   73792       ['up_sampling2d_29[0][0]']       \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 16, 16, 256)  295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 64, 64, 64)  256         ['conv2d_218[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 16, 16, 256)  590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 64, 64, 64)   0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 16, 16, 256)  590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)            (None, 64, 64, 64)   4160        ['activation_181[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)            (None, 64, 64, 64)   256         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 8, 8, 256)    0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 64, 64, 64)  256         ['conv2d_219[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 64, 64, 64)  256         ['conv2d_220[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 8, 8, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 64, 64, 64)   0           ['batch_normalization_145[0][0]',\n",
            "                                                                  'batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 8, 8, 512)    2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 64, 64, 64)   0           ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 8, 8, 512)    2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)            (None, 64, 64, 1)    65          ['activation_182[0][0]']         \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 4, 4, 512)    0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 64, 64, 1)   4           ['conv2d_221[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 64, 64, 1)    0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)         (None, 64, 64, 3)    0           ['input_1[0][0]',                \n",
            "                                                                  'activation_183[0][0]']         \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 64, 64, 67)   0           ['activation_181[0][0]',         \n",
            "                                                                  'multiply_29[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 4, 4, 1024)   0           ['activation_165[0][0]',         \n",
            "                                                                  'block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)            (None, 64, 64, 64)   38656       ['concatenate_32[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)            (None, 4, 4, 32)     294944      ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 64, 64, 64)   0           ['conv2d_222[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)            (None, 4, 4, 3)      99          ['conv2d_225[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)            (None, 64, 64, 64)   36928       ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 3)           0           ['conv2d_226[0][0]']             \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 64, 64, 64)   0           ['conv2d_223[0][0]']             \n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 3)            0           ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)            (None, 64, 64, 3)    195         ['activation_185[0][0]']         \n",
            "                                                                                                  \n",
            " classification (Reshape)       (None, 1, 1, 3)      0           ['activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " segmentation (Multiply)        (None, 64, 64, 3)    0           ['conv2d_224[0][0]',             \n",
            "                                                                  'classification[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 71,335,711\n",
            "Trainable params: 56,577,493\n",
            "Non-trainable params: 14,758,218\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQsWAMVEmQGE",
        "outputId": "d4ab4514-8961-4c2b-d92c-f159396ac7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "145/145 [==============================] - 16771s 114s/step - loss: 0.2556 - iou: 0.6815 - val_loss: 0.9982 - val_iou: 9.1456e-04\n",
            "Epoch 2/100\n",
            "145/145 [==============================] - 213s 741ms/step - loss: 0.0190 - iou: 0.9627 - val_loss: 1.0000 - val_iou: 1.8194e-05\n",
            "Epoch 3/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0152 - iou: 0.9699 - val_loss: 1.0000 - val_iou: 7.6629e-06\n",
            "Epoch 4/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0126 - iou: 0.9752 - val_loss: 0.9479 - val_iou: 0.0271\n",
            "Epoch 5/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0200 - iou: 0.9616 - val_loss: 0.8292 - val_iou: 0.0936\n",
            "Epoch 6/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0163 - iou: 0.9679 - val_loss: 0.8596 - val_iou: 0.0761\n",
            "Epoch 7/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0119 - iou: 0.9766 - val_loss: 0.6788 - val_iou: 0.1927\n",
            "Epoch 8/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0100 - iou: 0.9802 - val_loss: 0.1010 - val_iou: 0.8169\n",
            "Epoch 9/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0094 - iou: 0.9814 - val_loss: 0.0150 - val_iou: 0.9704\n",
            "Epoch 10/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0086 - iou: 0.9829 - val_loss: 0.0119 - val_iou: 0.9765\n",
            "Epoch 11/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0080 - iou: 0.9841 - val_loss: 0.0097 - val_iou: 0.9808\n",
            "Epoch 12/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0076 - iou: 0.9849 - val_loss: 0.0100 - val_iou: 0.9801\n",
            "Epoch 13/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0074 - iou: 0.9854 - val_loss: 0.0082 - val_iou: 0.9838\n",
            "Epoch 14/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0069 - iou: 0.9863 - val_loss: 0.0076 - val_iou: 0.9849\n",
            "Epoch 15/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0067 - iou: 0.9866 - val_loss: 0.0083 - val_iou: 0.9835\n",
            "Epoch 16/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0063 - iou: 0.9874 - val_loss: 0.0067 - val_iou: 0.9866\n",
            "Epoch 17/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0061 - iou: 0.9879 - val_loss: 0.0077 - val_iou: 0.9848\n",
            "Epoch 18/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0061 - iou: 0.9878 - val_loss: 0.0070 - val_iou: 0.9862\n",
            "Epoch 19/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0057 - iou: 0.9886 - val_loss: 0.0071 - val_iou: 0.9859\n",
            "Epoch 20/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0057 - iou: 0.9886 - val_loss: 0.0070 - val_iou: 0.9862\n",
            "Epoch 21/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0125 - iou: 0.9753 - val_loss: 0.0192 - val_iou: 0.9623\n",
            "Epoch 22/100\n",
            "145/145 [==============================] - 107s 737ms/step - loss: 0.0068 - iou: 0.9864 - val_loss: 0.0122 - val_iou: 0.9759\n",
            "Epoch 23/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0060 - iou: 0.9881 - val_loss: 0.0076 - val_iou: 0.9849\n",
            "Epoch 24/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0055 - iou: 0.9890 - val_loss: 0.0063 - val_iou: 0.9874\n",
            "Epoch 25/100\n",
            "145/145 [==============================] - 107s 742ms/step - loss: 0.0051 - iou: 0.9899 - val_loss: 0.0068 - val_iou: 0.9864\n",
            "Epoch 26/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0051 - iou: 0.9898 - val_loss: 0.0059 - val_iou: 0.9882\n",
            "Epoch 27/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0051 - iou: 0.9899 - val_loss: 0.0062 - val_iou: 0.9876\n",
            "Epoch 28/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0050 - iou: 0.9901 - val_loss: 0.0068 - val_iou: 0.9865\n",
            "Epoch 29/100\n",
            "145/145 [==============================] - 107s 742ms/step - loss: 0.0048 - iou: 0.9904 - val_loss: 0.0059 - val_iou: 0.9883\n",
            "Epoch 30/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0047 - iou: 0.9907 - val_loss: 0.0061 - val_iou: 0.9879\n",
            "Epoch 31/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0047 - iou: 0.9906 - val_loss: 0.0064 - val_iou: 0.9873\n",
            "Epoch 32/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0045 - iou: 0.9910 - val_loss: 0.0058 - val_iou: 0.9885\n",
            "Epoch 33/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0045 - iou: 0.9910 - val_loss: 0.0054 - val_iou: 0.9893\n",
            "Epoch 34/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0044 - iou: 0.9913 - val_loss: 0.0058 - val_iou: 0.9886\n",
            "Epoch 35/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0045 - iou: 0.9911 - val_loss: 0.0053 - val_iou: 0.9894\n",
            "Epoch 36/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0076 - iou: 0.9852 - val_loss: 0.9114 - val_iou: 0.0464\n",
            "Epoch 37/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0110 - iou: 0.9783 - val_loss: 0.0091 - val_iou: 0.9820\n",
            "Epoch 38/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0062 - iou: 0.9877 - val_loss: 0.0075 - val_iou: 0.9850\n",
            "Epoch 39/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0051 - iou: 0.9898 - val_loss: 0.0080 - val_iou: 0.9841\n",
            "Epoch 40/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0046 - iou: 0.9909 - val_loss: 0.0062 - val_iou: 0.9878\n",
            "Epoch 41/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0044 - iou: 0.9912 - val_loss: 0.0061 - val_iou: 0.9879\n",
            "Epoch 42/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0043 - iou: 0.9913 - val_loss: 0.0058 - val_iou: 0.9885\n",
            "Epoch 43/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0042 - iou: 0.9916 - val_loss: 0.0054 - val_iou: 0.9892\n",
            "Epoch 44/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0042 - iou: 0.9916 - val_loss: 0.0056 - val_iou: 0.9889\n",
            "Epoch 45/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0040 - iou: 0.9920 - val_loss: 0.0060 - val_iou: 0.9881\n",
            "Epoch 46/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0040 - iou: 0.9919 - val_loss: 0.0050 - val_iou: 0.9900\n",
            "Epoch 47/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0040 - iou: 0.9921 - val_loss: 0.0055 - val_iou: 0.9891\n",
            "Epoch 48/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0039 - iou: 0.9921 - val_loss: 0.0051 - val_iou: 0.9898\n",
            "Epoch 49/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0041 - iou: 0.9919 - val_loss: 0.0058 - val_iou: 0.9884\n",
            "Epoch 50/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0039 - iou: 0.9922 - val_loss: 0.0053 - val_iou: 0.9895\n",
            "Epoch 51/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0038 - iou: 0.9925 - val_loss: 0.0056 - val_iou: 0.9889\n",
            "Epoch 52/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0040 - iou: 0.9921 - val_loss: 0.0068 - val_iou: 0.9865\n",
            "Epoch 53/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0039 - iou: 0.9922 - val_loss: 0.0054 - val_iou: 0.9893\n",
            "Epoch 54/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0038 - iou: 0.9924 - val_loss: 0.0063 - val_iou: 0.9874\n",
            "Epoch 55/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0038 - iou: 0.9924 - val_loss: 0.0053 - val_iou: 0.9895\n",
            "Epoch 56/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0038 - iou: 0.9925 - val_loss: 0.0053 - val_iou: 0.9895\n",
            "Epoch 57/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0039 - iou: 0.9922 - val_loss: 0.0066 - val_iou: 0.9870\n",
            "Epoch 58/100\n",
            "145/145 [==============================] - 107s 737ms/step - loss: 0.0038 - iou: 0.9923 - val_loss: 0.0053 - val_iou: 0.9895\n",
            "Epoch 59/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0040 - iou: 0.9921 - val_loss: 0.0053 - val_iou: 0.9894\n",
            "Epoch 60/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0037 - iou: 0.9926 - val_loss: 0.0056 - val_iou: 0.9889\n",
            "Epoch 61/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0039 - iou: 0.9922 - val_loss: 0.0062 - val_iou: 0.9877\n",
            "Epoch 62/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0038 - iou: 0.9924 - val_loss: 0.0056 - val_iou: 0.9888\n",
            "Epoch 63/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0038 - iou: 0.9925 - val_loss: 0.0052 - val_iou: 0.9896\n",
            "Epoch 64/100\n",
            "145/145 [==============================] - 107s 742ms/step - loss: 0.0038 - iou: 0.9923 - val_loss: 0.0051 - val_iou: 0.9899\n",
            "Epoch 65/100\n",
            "145/145 [==============================] - 107s 737ms/step - loss: 0.0038 - iou: 0.9925 - val_loss: 0.0053 - val_iou: 0.9895\n",
            "Epoch 66/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0038 - iou: 0.9924 - val_loss: 0.0054 - val_iou: 0.9892\n",
            "Epoch 67/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0036 - iou: 0.9928 - val_loss: 0.0054 - val_iou: 0.9893\n",
            "Epoch 68/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0036 - iou: 0.9928 - val_loss: 0.0052 - val_iou: 0.9897\n",
            "Epoch 69/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0036 - iou: 0.9929 - val_loss: 0.0060 - val_iou: 0.9881\n",
            "Epoch 70/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0036 - iou: 0.9928 - val_loss: 0.0054 - val_iou: 0.9893\n",
            "Epoch 71/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0036 - iou: 0.9928 - val_loss: 0.0051 - val_iou: 0.9898\n",
            "Epoch 72/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0035 - iou: 0.9930 - val_loss: 0.0052 - val_iou: 0.9897\n",
            "Epoch 73/100\n",
            "145/145 [==============================] - 108s 743ms/step - loss: 0.0038 - iou: 0.9925 - val_loss: 0.0055 - val_iou: 0.9891\n",
            "Epoch 74/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0037 - iou: 0.9927 - val_loss: 0.0050 - val_iou: 0.9900\n",
            "Epoch 75/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0035 - iou: 0.9930 - val_loss: 0.0060 - val_iou: 0.9881\n",
            "Epoch 76/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0036 - iou: 0.9929 - val_loss: 0.0056 - val_iou: 0.9888\n",
            "Epoch 77/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0034 - iou: 0.9932 - val_loss: 0.0051 - val_iou: 0.9899\n",
            "Epoch 78/100\n",
            "145/145 [==============================] - 107s 737ms/step - loss: 0.0036 - iou: 0.9929 - val_loss: 0.0055 - val_iou: 0.9890\n",
            "Epoch 79/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0054 - iou: 0.9893 - val_loss: 0.7386 - val_iou: 0.1519\n",
            "Epoch 80/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0097 - iou: 0.9809 - val_loss: 0.0065 - val_iou: 0.9871\n",
            "Epoch 81/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0046 - iou: 0.9909 - val_loss: 0.0057 - val_iou: 0.9887\n",
            "Epoch 82/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0038 - iou: 0.9924 - val_loss: 0.0054 - val_iou: 0.9893\n",
            "Epoch 83/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0034 - iou: 0.9932 - val_loss: 0.0053 - val_iou: 0.9895\n",
            "Epoch 84/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0033 - iou: 0.9935 - val_loss: 0.0046 - val_iou: 0.9908\n",
            "Epoch 85/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0032 - iou: 0.9936 - val_loss: 0.0045 - val_iou: 0.9911\n",
            "Epoch 86/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0031 - iou: 0.9938 - val_loss: 0.0044 - val_iou: 0.9912\n",
            "Epoch 87/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0032 - iou: 0.9936 - val_loss: 0.0048 - val_iou: 0.9905\n",
            "Epoch 88/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0030 - iou: 0.9939 - val_loss: 0.0043 - val_iou: 0.9914\n",
            "Epoch 89/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0030 - iou: 0.9941 - val_loss: 0.0047 - val_iou: 0.9907\n",
            "Epoch 90/100\n",
            "145/145 [==============================] - 107s 741ms/step - loss: 0.0030 - iou: 0.9941 - val_loss: 0.0043 - val_iou: 0.9915\n",
            "Epoch 91/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0030 - iou: 0.9940 - val_loss: 0.0047 - val_iou: 0.9906\n",
            "Epoch 92/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0031 - iou: 0.9939 - val_loss: 0.0049 - val_iou: 0.9903\n",
            "Epoch 93/100\n",
            "145/145 [==============================] - 107s 740ms/step - loss: 0.0031 - iou: 0.9938 - val_loss: 0.0045 - val_iou: 0.9910\n",
            "Epoch 94/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0031 - iou: 0.9938 - val_loss: 0.0046 - val_iou: 0.9909\n",
            "Epoch 95/100\n",
            "145/145 [==============================] - 108s 742ms/step - loss: 0.0031 - iou: 0.9939 - val_loss: 0.0048 - val_iou: 0.9905\n",
            "Epoch 96/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0033 - iou: 0.9934 - val_loss: 0.0047 - val_iou: 0.9906\n",
            "Epoch 97/100\n",
            "145/145 [==============================] - 107s 738ms/step - loss: 0.0032 - iou: 0.9937 - val_loss: 0.0046 - val_iou: 0.9908\n",
            "Epoch 98/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0031 - iou: 0.9939 - val_loss: 0.0050 - val_iou: 0.9901\n",
            "Epoch 99/100\n",
            "145/145 [==============================] - 107s 739ms/step - loss: 0.0030 - iou: 0.9939 - val_loss: 0.0071 - val_iou: 0.9859\n",
            "Epoch 100/100\n",
            "145/145 [==============================] - 107s 737ms/step - loss: 0.0030 - iou: 0.9940 - val_loss: 0.0051 - val_iou: 0.9899\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_generator,\n",
        "                    steps_per_epoch=EPOCH_STEP_TRAIN,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=EPOCH_STEP_TEST,\n",
        "                   epochs=NUM_OF_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZnJIJTtMFTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d290f96d-f7fe-4bd5-8fa1-2f22c34b1b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to disk.\n"
          ]
        }
      ],
      "source": [
        "loss_name=\"\"\n",
        "if LOSS_FUNC_DICE:\n",
        "  loss_name=\"Dice\"\n",
        "if LOSS_FUNC_TRAV:\n",
        "  loss_name=\"Tver\"\n",
        "# Serialize model to JSON:\n",
        "model_json = model.to_json()\n",
        "with open(f'/content/drive/My Drive/KneeProject/models/{model.name}_({IMAGE_HEIGHT}_{IMAGE_WIDTH})_epochs:{NUM_OF_EPOCHS}_learning:{LEARNING_RATE}_loss:{loss_name}_batch:{BATCH_SIZE_TRAIN}.json', \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Serialize weights to HDF5 (h5py needed):\n",
        "model.save_weights(f'/content/drive/My Drive/KneeProject/models/{model.name}_({IMAGE_HEIGHT}_{IMAGE_WIDTH})_epochs:{NUM_OF_EPOCHS}_learning:{LEARNING_RATE}_loss:{loss_name}_batch:{BATCH_SIZE_TRAIN}.h5')\n",
        "\n",
        "with open(f'/content/drive/My Drive/KneeProject/models/{model.name}_({IMAGE_HEIGHT}_{IMAGE_WIDTH})_epochs:{NUM_OF_EPOCHS}_learning:{LEARNING_RATE}_loss:{loss_name}_batch:{BATCH_SIZE_TRAIN}.pkl', 'wb') as f:\n",
        "    pickle.dump(history, f)\n",
        "\n",
        "print(\"Model saved to disk.\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UdfVw5BZD2SM",
        "levwwHhMEGm8",
        "vniWhVcMEmj-"
      ],
      "provenance": [],
      "gpuType": "A100",
      "gpuClass": "premium",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
